{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled1.ipynb","provenance":[],"authorship_tag":"ABX9TyOy83NMBy4N2mbxAuYPXhvP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":134},"id":"0FIrPBwg4TNO","executionInfo":{"status":"error","timestamp":1629267071869,"user_tz":-540,"elapsed":19,"user":{"displayName":"뚜뚜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYh6WlXFq1X6XUJHBbCx-VfyZqesyHJAoYJep2Yw=s64","userId":"15837783100942680972"}},"outputId":"4b3338c5-2ea7-45ad-bfbb-3e0c58ead6a7"},"source":["\"\"\"\n","RNN : 이미지를 막 쪼개서, \n","INPUT DATA가 시계열적 특성 갖고 있을 때 활용할 수 있는 레이어\n","오퍼레이션담당의 유닛에 따라 종류가 나뉨.\n","LSTM - 바닐라RNN은, X데이터가 들어오면 행렬 W가 곱해지고, 이전 STATE에서의 결과물인\n","Ht-1을 행렬 U와 곱하고 bias를 더해서 hyperbolic탄젠트 취한 것을 아웃풋으로 뽑거나,\n","다음 레이어의 인풋으로 들여보냄\n","여기서 LSTM은 더 나아가, 과거의 값이 최종값에 영향을 주기 힘든 기존 바닐라를 개선해,\n","INPUT을 받아 다음 레이어의 OPERATION으로 바로 보내는 길을 만듬\n","\"\"\""],"execution_count":1,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-e4615a684824>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"]}]},{"cell_type":"code","metadata":{"id":"_GPQwRZx4nC4","executionInfo":{"status":"ok","timestamp":1629269234532,"user_tz":-540,"elapsed":256,"user":{"displayName":"뚜뚜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYh6WlXFq1X6XUJHBbCx-VfyZqesyHJAoYJep2Yw=s64","userId":"15837783100942680972"}}},"source":["import tensorflow as tf\n","from keras.models import Model\n","from keras.layers import Input, Dense, LSTM\n","import numpy as np\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","x = np.array([[[1.], [2.], [3.], [4.], [5.]], [[2.], [3.], [4.], [5.], [6.]],\n","              [[3.],[4.],[5.],[6.],[7.]]])\n","y = np.array([[6.],[7.],[8.]])"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pm7tpy5e-yPY","executionInfo":{"status":"ok","timestamp":1629269165064,"user_tz":-540,"elapsed":361,"user":{"displayName":"뚜뚜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYh6WlXFq1X6XUJHBbCx-VfyZqesyHJAoYJep2Yw=s64","userId":"15837783100942680972"}},"outputId":"d64c3fa4-49df-42a1-fc8f-b97f346db420"},"source":["x.shape, y.shape # 차원. 하나의 데이터포인트가 가지는 개수가 5\n","#총 3개의 12345 23456 34567, 각각 5개이며, feautur demand는 1. 각 [1.]에 든 것 개수\n","#만약 이미지데이터라면, [1., 0., 1...]일 것이다. 이 경우엔 1이 아닐것"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((3, 5, 1), (3, 1))"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jBQV2JEa_N7B","executionInfo":{"status":"ok","timestamp":1629269240307,"user_tz":-540,"elapsed":694,"user":{"displayName":"뚜뚜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYh6WlXFq1X6XUJHBbCx-VfyZqesyHJAoYJep2Yw=s64","userId":"15837783100942680972"}},"outputId":"0376b4db-04ac-4f9d-a28b-502b6ced1ccf"},"source":["inputs = Input(batch_shape = (None, 5, 1))\n","h = LSTM(3)(inputs)\n","\"\"\"\n","LSTM레이어 정의에, 앞서말한 5가 쓰임. 위의 INPUT은 X를 받아오는데, \n","이 SHAPE은, 5라 정의 되어있어야, LSTM이 이를 받아올 때 5번계산을해야 함을 알수있음\n","5,1을 넘겨주게 되면, LSTM을 생성. KERAS LAYER밑에 정의되어 있으며, \n","(3)은, 아웃풋으로 내보낼 FEATURE DIMENSION. F통해 계산한 결과가 H인데, 이 H에 해당하는\n","SHAPE이 3으로 정의시킨 것. 이는 정의하기 나름이여, 결과 Output shape는 model.summary()\n","통해 알 수있을 것. 모델 경량화를 위한다면 이 모델을 줄이라.\n","output dimension은 1이어야 한다. y의 shape이, 출력해야하는 값이 [6.]이나 [7.]형태로\n","하나씩 들어있기에, dimension값은 1이어야 한다. \n","따라서, 최종적으로 Dense의 첫번째 인자는 1.\n","물론 아래 아웃풋을 없애고, outputs = LSTM(1)(inputs)로 해도 되지만, fully connected를\n","한번더 실행했다.\n","아담 옵티파이저, mean_squared_error사용.\n","최종 파라미터는 64개 등장.\n","\"\"\"\n","outputs = Dense(1, activation = 'relu')(h)\n","\n","model = Model(inputs, outputs)\n","opt = keras.optimizers.Adam(learning_rate = 0.01)\n","model.compile(loss = 'mean_squared_error', optimizer = opt)\n","\n","model.summary()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Model: \"model_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_6 (InputLayer)         [(None, 5, 1)]            0         \n","_________________________________________________________________\n","lstm_5 (LSTM)                (None, 3)                 60        \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 1)                 4         \n","=================================================================\n","Total params: 64\n","Trainable params: 64\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m7aLsn8UB6By","executionInfo":{"status":"ok","timestamp":1629269529655,"user_tz":-540,"elapsed":6323,"user":{"displayName":"뚜뚜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYh6WlXFq1X6XUJHBbCx-VfyZqesyHJAoYJep2Yw=s64","userId":"15837783100942680972"}},"outputId":"5dc2cc16-a9a5-49c2-a4c5-5cab2906cb6c"},"source":["model.fit(x,y,epochs=200, batch_size = 1)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Epoch 1/200\n","3/3 [==============================] - 2s 6ms/step - loss: 45.3951\n","Epoch 2/200\n","3/3 [==============================] - 0s 5ms/step - loss: 41.9492\n","Epoch 3/200\n","3/3 [==============================] - 0s 5ms/step - loss: 40.0074\n","Epoch 4/200\n","3/3 [==============================] - 0s 5ms/step - loss: 38.3069\n","Epoch 5/200\n","3/3 [==============================] - 0s 5ms/step - loss: 36.6396\n","Epoch 6/200\n","3/3 [==============================] - 0s 6ms/step - loss: 35.1058\n","Epoch 7/200\n","3/3 [==============================] - 0s 5ms/step - loss: 33.6472\n","Epoch 8/200\n","3/3 [==============================] - 0s 6ms/step - loss: 32.3331\n","Epoch 9/200\n","3/3 [==============================] - 0s 7ms/step - loss: 30.9988\n","Epoch 10/200\n","3/3 [==============================] - 0s 5ms/step - loss: 29.7157\n","Epoch 11/200\n","3/3 [==============================] - 0s 5ms/step - loss: 28.5679\n","Epoch 12/200\n","3/3 [==============================] - 0s 5ms/step - loss: 27.4954\n","Epoch 13/200\n","3/3 [==============================] - 0s 5ms/step - loss: 26.4536\n","Epoch 14/200\n","3/3 [==============================] - 0s 5ms/step - loss: 25.4593\n","Epoch 15/200\n","3/3 [==============================] - 0s 6ms/step - loss: 24.5063\n","Epoch 16/200\n","3/3 [==============================] - 0s 7ms/step - loss: 23.6277\n","Epoch 17/200\n","3/3 [==============================] - 0s 5ms/step - loss: 22.7427\n","Epoch 18/200\n","3/3 [==============================] - 0s 5ms/step - loss: 21.8915\n","Epoch 19/200\n","3/3 [==============================] - 0s 5ms/step - loss: 21.0418\n","Epoch 20/200\n","3/3 [==============================] - 0s 5ms/step - loss: 20.2924\n","Epoch 21/200\n","3/3 [==============================] - 0s 6ms/step - loss: 19.4834\n","Epoch 22/200\n","3/3 [==============================] - 0s 6ms/step - loss: 18.7719\n","Epoch 23/200\n","3/3 [==============================] - 0s 6ms/step - loss: 18.1121\n","Epoch 24/200\n","3/3 [==============================] - 0s 9ms/step - loss: 17.4008\n","Epoch 25/200\n","3/3 [==============================] - 0s 5ms/step - loss: 16.7356\n","Epoch 26/200\n","3/3 [==============================] - 0s 8ms/step - loss: 16.1056\n","Epoch 27/200\n","3/3 [==============================] - 0s 6ms/step - loss: 15.4645\n","Epoch 28/200\n","3/3 [==============================] - 0s 6ms/step - loss: 14.8181\n","Epoch 29/200\n","3/3 [==============================] - 0s 7ms/step - loss: 14.2854\n","Epoch 30/200\n","3/3 [==============================] - 0s 7ms/step - loss: 13.7157\n","Epoch 31/200\n","3/3 [==============================] - 0s 6ms/step - loss: 13.1315\n","Epoch 32/200\n","3/3 [==============================] - 0s 5ms/step - loss: 12.6370\n","Epoch 33/200\n","3/3 [==============================] - 0s 7ms/step - loss: 12.0559\n","Epoch 34/200\n","3/3 [==============================] - 0s 7ms/step - loss: 11.5297\n","Epoch 35/200\n","3/3 [==============================] - 0s 5ms/step - loss: 11.0432\n","Epoch 36/200\n","3/3 [==============================] - 0s 5ms/step - loss: 10.4150\n","Epoch 37/200\n","3/3 [==============================] - 0s 5ms/step - loss: 9.8949\n","Epoch 38/200\n","3/3 [==============================] - 0s 5ms/step - loss: 9.1430\n","Epoch 39/200\n","3/3 [==============================] - 0s 6ms/step - loss: 8.3241\n","Epoch 40/200\n","3/3 [==============================] - 0s 7ms/step - loss: 7.4746\n","Epoch 41/200\n","3/3 [==============================] - 0s 5ms/step - loss: 6.5811\n","Epoch 42/200\n","3/3 [==============================] - 0s 5ms/step - loss: 5.7604\n","Epoch 43/200\n","3/3 [==============================] - 0s 6ms/step - loss: 5.0633\n","Epoch 44/200\n","3/3 [==============================] - 0s 6ms/step - loss: 4.4582\n","Epoch 45/200\n","3/3 [==============================] - 0s 9ms/step - loss: 4.0451\n","Epoch 46/200\n","3/3 [==============================] - 0s 7ms/step - loss: 3.5476\n","Epoch 47/200\n","3/3 [==============================] - 0s 7ms/step - loss: 3.2095\n","Epoch 48/200\n","3/3 [==============================] - 0s 6ms/step - loss: 2.8713\n","Epoch 49/200\n","3/3 [==============================] - 0s 5ms/step - loss: 2.6499\n","Epoch 50/200\n","3/3 [==============================] - 0s 7ms/step - loss: 2.3958\n","Epoch 51/200\n","3/3 [==============================] - 0s 5ms/step - loss: 2.1261\n","Epoch 52/200\n","3/3 [==============================] - 0s 6ms/step - loss: 1.9583\n","Epoch 53/200\n","3/3 [==============================] - 0s 9ms/step - loss: 1.7923\n","Epoch 54/200\n","3/3 [==============================] - 0s 4ms/step - loss: 1.6893\n","Epoch 55/200\n","3/3 [==============================] - 0s 8ms/step - loss: 1.5382\n","Epoch 56/200\n","3/3 [==============================] - 0s 5ms/step - loss: 1.4006\n","Epoch 57/200\n","3/3 [==============================] - 0s 5ms/step - loss: 1.3269\n","Epoch 58/200\n","3/3 [==============================] - 0s 5ms/step - loss: 1.2182\n","Epoch 59/200\n","3/3 [==============================] - 0s 6ms/step - loss: 1.1648\n","Epoch 60/200\n","3/3 [==============================] - 0s 5ms/step - loss: 1.0782\n","Epoch 61/200\n","3/3 [==============================] - 0s 6ms/step - loss: 1.0229\n","Epoch 62/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.9901\n","Epoch 63/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.9218\n","Epoch 64/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.8930\n","Epoch 65/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.8735\n","Epoch 66/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.8484\n","Epoch 67/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.8011\n","Epoch 68/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.7981\n","Epoch 69/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.7601\n","Epoch 70/200\n","3/3 [==============================] - 0s 8ms/step - loss: 0.7546\n","Epoch 71/200\n","3/3 [==============================] - 0s 8ms/step - loss: 0.7389\n","Epoch 72/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.7175\n","Epoch 73/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.7157\n","Epoch 74/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.6982\n","Epoch 75/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.6911\n","Epoch 76/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.6847\n","Epoch 77/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.6771\n","Epoch 78/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.6846\n","Epoch 79/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.6737\n","Epoch 80/200\n","3/3 [==============================] - 0s 4ms/step - loss: 0.6688\n","Epoch 81/200\n","3/3 [==============================] - 0s 4ms/step - loss: 0.6648\n","Epoch 82/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.6642\n","Epoch 83/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.6580\n","Epoch 84/200\n","3/3 [==============================] - 0s 12ms/step - loss: 0.6531\n","Epoch 85/200\n","3/3 [==============================] - 0s 8ms/step - loss: 0.6544\n","Epoch 86/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.6547\n","Epoch 87/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.6524\n","Epoch 88/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.6486\n","Epoch 89/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.6468\n","Epoch 90/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.6473\n","Epoch 91/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.6447\n","Epoch 92/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.6476\n","Epoch 93/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.6437\n","Epoch 94/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.6424\n","Epoch 95/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.6417\n","Epoch 96/200\n","3/3 [==============================] - 0s 8ms/step - loss: 0.6427\n","Epoch 97/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.6402\n","Epoch 98/200\n","3/3 [==============================] - 0s 8ms/step - loss: 0.6428\n","Epoch 99/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.6389\n","Epoch 100/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.6386\n","Epoch 101/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.6395\n","Epoch 102/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.6371\n","Epoch 103/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.6352\n","Epoch 104/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.6318\n","Epoch 105/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.6257\n","Epoch 106/200\n","3/3 [==============================] - 0s 8ms/step - loss: 0.6124\n","Epoch 107/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.5836\n","Epoch 108/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.5025\n","Epoch 109/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.4604\n","Epoch 110/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.4868\n","Epoch 111/200\n","3/3 [==============================] - 0s 9ms/step - loss: 0.5114\n","Epoch 112/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.4400\n","Epoch 113/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.4691\n","Epoch 114/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.4668\n","Epoch 115/200\n","3/3 [==============================] - 0s 4ms/step - loss: 0.4255\n","Epoch 116/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.3738\n","Epoch 117/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.3502\n","Epoch 118/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.3666\n","Epoch 119/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.3467\n","Epoch 120/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.3290\n","Epoch 121/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.3385\n","Epoch 122/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.3197\n","Epoch 123/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.2799\n","Epoch 124/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.2472\n","Epoch 125/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.2686\n","Epoch 126/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.2416\n","Epoch 127/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.2063\n","Epoch 128/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.1914\n","Epoch 129/200\n","3/3 [==============================] - 0s 8ms/step - loss: 0.1801\n","Epoch 130/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.1631\n","Epoch 131/200\n","3/3 [==============================] - 0s 10ms/step - loss: 0.1689\n","Epoch 132/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.1486\n","Epoch 133/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.1454\n","Epoch 134/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.1371\n","Epoch 135/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.1369\n","Epoch 136/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.1280\n","Epoch 137/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.1438\n","Epoch 138/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.1285\n","Epoch 139/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.1385\n","Epoch 140/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.1260\n","Epoch 141/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.1522\n","Epoch 142/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.1684\n","Epoch 143/200\n","3/3 [==============================] - 0s 9ms/step - loss: 0.1367\n","Epoch 144/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.2935\n","Epoch 145/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.2412\n","Epoch 146/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.1140\n","Epoch 147/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.2817\n","Epoch 148/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.1037\n","Epoch 149/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.2637\n","Epoch 150/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.2486\n","Epoch 151/200\n","3/3 [==============================] - 0s 8ms/step - loss: 0.1213\n","Epoch 152/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.1332\n","Epoch 153/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.1224\n","Epoch 154/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.1088\n","Epoch 155/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.1046\n","Epoch 156/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.0915\n","Epoch 157/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.0833\n","Epoch 158/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.0836\n","Epoch 159/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.0798\n","Epoch 160/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.0752\n","Epoch 161/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.0801\n","Epoch 162/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.0740\n","Epoch 163/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.0708\n","Epoch 164/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.0679\n","Epoch 165/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.0701\n","Epoch 166/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.0651\n","Epoch 167/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.0659\n","Epoch 168/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.0674\n","Epoch 169/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.0655\n","Epoch 170/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.0656\n","Epoch 171/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.0635\n","Epoch 172/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.0643\n","Epoch 173/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.0604\n","Epoch 174/200\n","3/3 [==============================] - 0s 8ms/step - loss: 0.0566\n","Epoch 175/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.0558\n","Epoch 176/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.0535\n","Epoch 177/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.0535\n","Epoch 178/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.0549\n","Epoch 179/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.0565\n","Epoch 180/200\n","3/3 [==============================] - 0s 4ms/step - loss: 0.0550\n","Epoch 181/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.0468\n","Epoch 182/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.0632\n","Epoch 183/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.0574\n","Epoch 184/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.0515\n","Epoch 185/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.0500\n","Epoch 186/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.0450\n","Epoch 187/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.0463\n","Epoch 188/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.0435\n","Epoch 189/200\n","3/3 [==============================] - 0s 4ms/step - loss: 0.0464\n","Epoch 190/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.0412\n","Epoch 191/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.0393\n","Epoch 192/200\n","3/3 [==============================] - 0s 8ms/step - loss: 0.0417\n","Epoch 193/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.0418\n","Epoch 194/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.0433\n","Epoch 195/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.0408\n","Epoch 196/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.0437\n","Epoch 197/200\n","3/3 [==============================] - 0s 6ms/step - loss: 0.0417\n","Epoch 198/200\n","3/3 [==============================] - 0s 7ms/step - loss: 0.0338\n","Epoch 199/200\n","3/3 [==============================] - 0s 4ms/step - loss: 0.0357\n","Epoch 200/200\n","3/3 [==============================] - 0s 5ms/step - loss: 0.0420\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fbd2f8b0bd0>"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Kx-fKu2CEXK","executionInfo":{"status":"ok","timestamp":1629269562976,"user_tz":-540,"elapsed":707,"user":{"displayName":"뚜뚜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYh6WlXFq1X6XUJHBbCx-VfyZqesyHJAoYJep2Yw=s64","userId":"15837783100942680972"}},"outputId":"aa7f6540-dc25-44d5-9eb2-89f8fde6dbbe"},"source":["# 위의 결과를 보면, loss가 굉장히 감소함\n","model.predict(x)\n","#predict값은, 6, 7, 8에 어느정도 근접한 것을 알 수 있다.\n","#시계열정도에 따라 영향주는 정도를 알고싶다? 과거 2개의 스텝을 더 위주로 봐서 최종결과 내기 등\n","\"\"\"\n","시계열적 특성 반영코자 할때 RNN을 쓴다.\n","보통 언어모델에 쓰임.\n","\"\"\""],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[5.88652  ],\n","       [7.1066732],\n","       [7.7134056]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":15}]}]}