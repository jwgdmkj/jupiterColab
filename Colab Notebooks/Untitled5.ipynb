{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled5.ipynb","provenance":[],"authorship_tag":"ABX9TyNH4XDGal1KJQiCqe4DSPP+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":261},"id":"3k5Rb97PZRD9","executionInfo":{"status":"ok","timestamp":1639459538681,"user_tz":-540,"elapsed":31564,"user":{"displayName":"뚜뚜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYh6WlXFq1X6XUJHBbCx-VfyZqesyHJAoYJep2Yw=s64","userId":"15837783100942680972"}},"outputId":"aa5740fa-4514-4526-a473-20806e426f21"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","84131840/84125825 [==============================] - 1s 0us/step\n","84140032/84125825 [==============================] - 1s 0us/step\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>This is a short, crudely animated series by Da...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>The acting in this movie was superb. As an ama...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Okay, so the plot is on shaky ground. Yeah, al...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>It's been a long time since I saw this mini-se...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>A SHIRLEY TEMPLE Short Subject.&lt;br /&gt;&lt;br /&gt;It ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review  sentiment\n","0  This is a short, crudely animated series by Da...          1\n","1  The acting in this movie was superb. As an ama...          1\n","2  Okay, so the plot is on shaky ground. Yeah, al...          1\n","3  It's been a long time since I saw this mini-se...          1\n","4  A SHIRLEY TEMPLE Short Subject.<br /><br />It ...          1"]},"metadata":{},"execution_count":1}],"source":["import os\n","import re\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras import utils\n","data_set = tf.keras.utils.get_file(\n","    fname='imdb.tar.gz',\n","    origin='http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz',\n","    extract = True\n",")\n","\n","def directory_data(directory):\n","  data = {}\n","  data[\"review\"] = []\n","  for file_path in os.listdir(directory):\n","    with open(os.path.join(directory, file_path), \"r\", encoding='utf-8') as file:\n","      data[\"review\"].append(file.read())\n","  return pd.DataFrame.from_dict(data)\n","\n","def data(directory):\n","  pos_df = directory_data(os.path.join(directory, \"pos\"))\n","  neg_df = directory_data(os.path.join(directory, \"neg\"))\n","  pos_df[\"sentiment\"] = 1\n","  neg_df[\"sentiment\"] = 0\n","  return pd.concat([pos_df, neg_df])\n","\n","train_df = data(os.path.join(os.path.dirname(data_set),\"aclImdb\", \"train\"))\n","test_df = data(os.path.join(os.path.dirname(data_set),\"aclImdb\", \"test\"))\n","\n","train_df.head()"]},{"cell_type":"code","source":["!pip install feedparser\n","!pip install newspaper3k\n","!pip install konlpy\n","!pip install bs4\n","!sudo apt-get install -y fonts-nanum\n","!sudo fc-cache -fv\n","!rm ~/.cache/matplotlib =rf"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ePR6zBfezQC","executionInfo":{"status":"ok","timestamp":1639460936102,"user_tz":-540,"elapsed":32493,"user":{"displayName":"뚜뚜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYh6WlXFq1X6XUJHBbCx-VfyZqesyHJAoYJep2Yw=s64","userId":"15837783100942680972"}},"outputId":"84c6d07f-1084-4830-a234-eef44e17b348"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting feedparser\n","  Downloading feedparser-6.0.8-py3-none-any.whl (81 kB)\n","\u001b[?25l\r\u001b[K     |████                            | 10 kB 26.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 20 kB 28.0 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 40 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 51 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 61 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 71 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81 kB 4.8 MB/s \n","\u001b[?25hCollecting sgmllib3k\n","  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n","Building wheels for collected packages: sgmllib3k\n","  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6065 sha256=b2797cc1b18b58576070e03e72fbc7cebbf523364bd7eff890b86e94a4a63cec\n","  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n","Successfully built sgmllib3k\n","Installing collected packages: sgmllib3k, feedparser\n","Successfully installed feedparser-6.0.8 sgmllib3k-1.0.0\n","Collecting newspaper3k\n","  Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n","\u001b[K     |████████████████████████████████| 211 kB 8.0 MB/s \n","\u001b[?25hCollecting tinysegmenter==0.3\n","  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n","Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.2.6)\n","Collecting jieba3k>=0.35.1\n","  Downloading jieba3k-0.35.1.zip (7.4 MB)\n","\u001b[K     |████████████████████████████████| 7.4 MB 57.0 MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.8.2)\n","Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (6.0.8)\n","Collecting cssselect>=0.9.2\n","  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (4.6.3)\n","Collecting feedfinder2>=0.0.4\n","  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n","Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.13)\n","Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (2.23.0)\n","Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (3.2.5)\n","Collecting tldextract>=2.0.1\n","  Downloading tldextract-3.1.2-py2.py3-none-any.whl (87 kB)\n","\u001b[K     |████████████████████████████████| 87 kB 6.1 MB/s \n","\u001b[?25hRequirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from newspaper3k) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.15.0)\n","Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.7/dist-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.10.0->newspaper3k) (2021.10.8)\n","Collecting requests-file>=1.4\n","  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n","Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.4.0)\n","Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k\n","  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13552 sha256=245084b5d577cf7ae3b7dc836d23e0e841130660868acc22f9139ee250e1006b\n","  Stored in directory: /root/.cache/pip/wheels/df/67/41/faca10fa501ca010be41b49d40360c2959e1c4f09bcbfa37fa\n","  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3356 sha256=b0b6e9874b0c20eca0abbf7921364a3d5423f4c21afeb11c6ff1efb2e5c7b5f9\n","  Stored in directory: /root/.cache/pip/wheels/7f/d4/8f/6e2ca54744c9d7292d88ddb8d42876bcdab5e6d84a21c10346\n","  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398405 sha256=cd947b5d742b0816674e33de12154e68b180300fe8694e3ed63a2f5838094aac\n","  Stored in directory: /root/.cache/pip/wheels/4c/91/46/3c208287b726df325a5979574324878b679116e4baae1af3c3\n","Successfully built tinysegmenter feedfinder2 jieba3k\n","Installing collected packages: requests-file, tldextract, tinysegmenter, jieba3k, feedfinder2, cssselect, newspaper3k\n","Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 tinysegmenter-0.3 tldextract-3.1.2\n","Collecting konlpy\n","  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n","\u001b[K     |████████████████████████████████| 19.4 MB 1.2 MB/s \n","\u001b[?25hCollecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n","Collecting JPype1>=0.7.0\n","  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n","\u001b[K     |████████████████████████████████| 448 kB 32.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n","Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n","Collecting beautifulsoup4==4.6.0\n","  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 7.3 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.10.8)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n","Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n","  Attempting uninstall: beautifulsoup4\n","    Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n","Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.0)\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following NEW packages will be installed:\n","  fonts-nanum\n","0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n","Need to get 9,604 kB of archives.\n","After this operation, 29.5 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 fonts-nanum all 20170925-1 [9,604 kB]\n","Fetched 9,604 kB in 2s (5,311 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package fonts-nanum.\n","(Reading database ... 155222 files and directories currently installed.)\n","Preparing to unpack .../fonts-nanum_20170925-1_all.deb ...\n","Unpacking fonts-nanum (20170925-1) ...\n","Setting up fonts-nanum (20170925-1) ...\n","Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n","/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n","/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n","/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n","/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n","/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n","/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n","/root/.local/share/fonts: skipping, no such directory\n","/root/.fonts: skipping, no such directory\n","/var/cache/fontconfig: cleaning cache directory\n","/root/.cache/fontconfig: not cleaning non-existent cache directory\n","/root/.fontconfig: not cleaning non-existent cache directory\n","fc-cache: succeeded\n","rm: cannot remove '/root/.cache/matplotlib': Is a directory\n","rm: cannot remove '=rf': No such file or directory\n"]}]},{"cell_type":"code","source":["import feedparser\n","from newspaper import Article\n","from konlpy.tag import Okt\n","from collections import Counter\n","from operator import eq\n","import numpy as np\n","from bs4 import BeautifulSoup"],"metadata":{"id":"lpmdgQkLfiPS","executionInfo":{"status":"ok","timestamp":1639462170820,"user_tz":-540,"elapsed":594,"user":{"displayName":"뚜뚜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYh6WlXFq1X6XUJHBbCx-VfyZqesyHJAoYJep2Yw=s64","userId":"15837783100942680972"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["urls = [\"http://rss.etnews.com/Section901.xml\",\n","        \"http://rss.etnews.com/Section902.xml\"]\n","\n","article_list = cralw_rss(urls)"],"metadata":{"id":"VKRLygJpfiT8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_tags(text, ntags=50) :\n","  num_unique_words = 0\n","  num_most_freq = 0\n","  ranking = 0\n","  spliter = 0kt()\n","  nouns = spliter.nouns(text)\n","  count = Counter(nouns)"],"metadata":{"id":"iDnPFor_sEKp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Enter your query: ')\n","query = input()\n","for article in article_list :\n","  n, _ = Howmanywords(query, article['tags'])\n","  if n!= 0:\n","    print('TF: ', n, article['title'], article['link'], '\\n');\n","\n","def Howmanywords(request, tag):\n","  nWords = 0\n","  nRanking = 0\n","  for n in tag:\n","    noun = n['tag']\n","    count = n['count']\n","    rank = n['ranking']\n","\n","    if eq(noun, request) :\n","      nWords = count\n","      nRanking = rank\n","  return nWords, nRanking"],"metadata":{"id":"RHjK8hqK0c7m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"iKH8xu9m0d6e"},"execution_count":null,"outputs":[]}]}