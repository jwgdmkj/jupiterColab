{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Text_1213.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNk8hD/TfArjdTdSxyvZ9ZB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":27,"metadata":{"id":"5nBZ-xKDdKoW","executionInfo":{"status":"ok","timestamp":1639382700864,"user_tz":-540,"elapsed":36336,"user":{"displayName":"뚜뚜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYh6WlXFq1X6XUJHBbCx-VfyZqesyHJAoYJep2Yw=s64","userId":"15837783100942680972"}}},"outputs":[],"source":["import numpy as np\n","from sklearn.metrics import jaccard_score\n","from sklearn.metrics import accuracy_score\n","\n","# print(jaccard_score(np.array([1,2,3]), np.array([1,4,5]), average='weighted'))\n","# print(jaccard_score(np.array([1,3,2]), np.array([4,1,5]), average='weighted'))\n","# print(jaccard_score(np.array([1,1,0, 0]), np.array([1,1,0, 2]), average='weighted'))\n","# print(jaccard_score(np.array([1,0,1,0]), np.array([1,1,0, 2]), average = 'micro'))\n","\n","# print(accuracy_score(np.array([1,2,3]), np.array([1,4,5])))\n","# print(accuracy_score(np.array([1,3,2]), np.array([4,1,5])))\n","# print(accuracy_score(np.array([1,1,0, 0]), np.array([1,1,0, 2])))\n","# print(accuracy_score(np.array([1,0,1,0]), np.array([1,1,0, 2])))\n","\n","#from sklearn.feature_extraction import TfidVectorizer\n","#sentence = ('')\n","\n","import os \n","import re\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras import utils\n","data_set =tf.keras.utils.get_file(\n","    fname=\"imdb.tar.gz\",\n","    origin=\"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n","    extract = True\n",")\n","def directory_data(directory):\n","  data={}\n","  data[\"review\"]=[]\n","  for file_path in os.listdir(directory):\n","    with open(os.path.join(directory, file_path), \"r\" , encoding='utf-8') as file:\n","      data[\"review\"].append(file.read())\n","      return pd.DataFrame.from_dict(data)\n","\n","def data(directory):\n","  pos_df= directory_data(os.path.join(directory, \"pos\"))\n","  neg_df = directory_data(os.path.join(directory,\"neg\"))\n","  pos_df[\"sentiment\"]=1\n","  neg_df[\"sentiment\"]=0\n","  return pd.concat([pos_df,neg_df])\n","\n","train_df = data(os.path.join(os.path.dirname(data_set), \"aclImdb\",\"train\"))\n","test_df = data(os.path.join(os.path.dirname(data_set),\"aclImdb\",\"test\"))\n","\n","reviews = list(train_df['review'])\n","tokenized_reviews = [r.split() for r in reviews]\n","review_len_by_token= [len(t) for t in tokenized_reviews]\n","review_len_by_alphabet = [len(s.replace(' ' , '')) for s in reviews]\n"]}]}