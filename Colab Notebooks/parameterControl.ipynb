{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"parameterControl.ipynb","provenance":[],"authorship_tag":"ABX9TyMPYwPkt3/Z0XT2/VQKhGpl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3dxd6OSU5BmH"},"source":["**HyperParameter Tuning**\n","\n","각 모델을 summary하는 과정에서, batch_size를 각자 다르게 해서 평가를 해본다.\n","batch_size의 수에 따른 정확도(learning_rate)를 평가하고, 어느 batch_size일 때 가장 수치가 괜찮은지 평가할 수 있다.\n","\n","랜덤서치 - 최솟값 ~ 최댓값 사이에서 값 랜덤으로 가져와, batch_size도 1 ~ 10사이에서 랜덤으로 뽑아, learning_rate도 랜덤으로 뿌려와 실험.\n","\n","learning_rate가 0.025부터 0.05, 0.1, 0.2.... 로 하고, batch_size를 1 2 4.. 로 하면 nm개의 칸을 만들어야 하는데, 이를 일일이 하면 시간이 걸린다.\n","어떻게 해야 효율적으로 할 수 있을까?"]},{"cell_type":"code","metadata":{"id":"QQhyrnll-8ur","executionInfo":{"status":"ok","timestamp":1632457651090,"user_tz":-540,"elapsed":3677,"user":{"displayName":"뚜뚜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYh6WlXFq1X6XUJHBbCx-VfyZqesyHJAoYJep2Yw=s64","userId":"15837783100942680972"}}},"source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import train_test_split\n","from sklearn import metrics\n","\n","from sklearn.linear_model import Lasso\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","with open('X.npy', 'rb') as f:\n","    X = np.load(f)\n","\n","with open('y.npy', 'rb') as f:\n","    y = np.load(f)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"4-vtfPQPE5RP","executionInfo":{"status":"ok","timestamp":1632458019635,"user_tz":-540,"elapsed":297,"user":{"displayName":"뚜뚜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYh6WlXFq1X6XUJHBbCx-VfyZqesyHJAoYJep2Yw=s64","userId":"15837783100942680972"}}},"source":["#K-fold cross validation : Data가 작을 때 validation accuracy를 믿고자 하면\n","\n","#초기는, X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, randoma_state =42)\n","#처럼, test_size를 0.1로 10% 잘라서 테스트를 하였다\n","X.shape, y.shape\n","\n","x_min_max_scaler = MinMaxScaler()\n","x_min_max_scaler.fit(X)\n","scaled_X = x_min_max_scaler.transform(X)\n","\n","y_min_max_scaler = MinMaxScaler()\n","y_min_max_scaler.fit(y)\n","scaled_y = y_min_max_scaler.transform(y)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"os4b8F45E9hb","executionInfo":{"status":"ok","timestamp":1632458021377,"user_tz":-540,"elapsed":305,"user":{"displayName":"뚜뚜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYh6WlXFq1X6XUJHBbCx-VfyZqesyHJAoYJep2Yw=s64","userId":"15837783100942680972"}}},"source":["# K-fold cross validation\n","K = 10\n","kf = KFold(n_splits=K)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xVnELxpiFHwL","executionInfo":{"status":"ok","timestamp":1632458035543,"user_tz":-540,"elapsed":12086,"user":{"displayName":"뚜뚜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYh6WlXFq1X6XUJHBbCx-VfyZqesyHJAoYJep2Yw=s64","userId":"15837783100942680972"}},"outputId":"76251b98-1d32-4463-ecf4-b3b736d0c082"},"source":["rmses = []\n","for train_index, test_index in kf.split(scaled_X):\n","  scaled_X_train, scaled_X_test = scaled_X[train_index], scaled_X[test_index]\n","  scaled_y_train, scaled_y_test = scaled_y[train_index], scaled_y[test_index]\n","  y_test = y[test_index]\n","\n","  # training\n","  model = keras.Sequential(\n","      [\n","          keras.Input(shape=scaled_X_train.shape[-1]),\n","          layers.Dense(96, activation='relu'),\n","          layers.Dense(48, activation='relu'),\n","          layers.Dense(1)\n","      ]\n","  )\n","\n","  opt = keras.optimizers.Adam(learning_rate=0.005)\n","  model.compile(loss=\"mse\", optimizer=opt)\n","\n","  early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7)\n","  model.fit(scaled_X_train, scaled_y_train, \n","            batch_size=2, epochs=150, \n","            callbacks=[early_stopping_callback], validation_split=0.05, verbose='auto')\n","\n","  # evaluation\n","  pred = model.predict(scaled_X_test).reshape((-1, 1))\n","  pred = y_min_max_scaler.inverse_transform(pred)\n","  rmse = np.sqrt(metrics.mean_squared_error(y_test, pred))\n","\n","  print(rmse)\n","  print(\"---------------------\")\n","  \n","  rmses.append(rmse)\n","  break\n","\n","print(\"average rmse:\", np.mean(rmses))"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/150\n","624/624 [==============================] - 2s 2ms/step - loss: 0.0067 - val_loss: 0.0024\n","Epoch 2/150\n","624/624 [==============================] - 1s 2ms/step - loss: 0.0046 - val_loss: 0.0023\n","Epoch 3/150\n","624/624 [==============================] - 1s 1ms/step - loss: 0.0033 - val_loss: 0.0013\n","Epoch 4/150\n","624/624 [==============================] - 1s 1ms/step - loss: 0.0041 - val_loss: 0.0021\n","Epoch 5/150\n","624/624 [==============================] - 1s 1ms/step - loss: 0.0034 - val_loss: 0.0015\n","Epoch 6/150\n","624/624 [==============================] - 1s 1ms/step - loss: 0.0034 - val_loss: 0.0022\n","Epoch 7/150\n","624/624 [==============================] - 1s 1ms/step - loss: 0.0031 - val_loss: 0.0017\n","Epoch 8/150\n","624/624 [==============================] - 1s 1ms/step - loss: 0.0028 - val_loss: 0.0016\n","Epoch 9/150\n","624/624 [==============================] - 1s 2ms/step - loss: 0.0032 - val_loss: 0.0015\n","Epoch 10/150\n","624/624 [==============================] - 1s 1ms/step - loss: 0.0024 - val_loss: 0.0020\n","29885.89341753142\n","---------------------\n","average rmse: 29885.89341753142\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PVt625lT-CHp","executionInfo":{"status":"ok","timestamp":1632458049845,"user_tz":-540,"elapsed":326,"user":{"displayName":"뚜뚜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYh6WlXFq1X6XUJHBbCx-VfyZqesyHJAoYJep2Yw=s64","userId":"15837783100942680972"}},"outputId":"f0238813-5031-4c36-e61d-d698abd7836a"},"source":["# Grid Search\n","# batch size와 learning rate를 설정해보낟\n","batch_sizes = np.arange(1, 10, 2)\n","learning_rates = [0.005, 0.01, 0.02]\n","\n","for batch_size in batch_sizes :\n","  for learning_rate in learning_rates:\n","    print(\"batch size: \", batch_size, \"learning rate: \", learning_rate)"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["batch size:  1 learning rate:  0.005\n","batch size:  1 learning rate:  0.01\n","batch size:  1 learning rate:  0.02\n","batch size:  3 learning rate:  0.005\n","batch size:  3 learning rate:  0.01\n","batch size:  3 learning rate:  0.02\n","batch size:  5 learning rate:  0.005\n","batch size:  5 learning rate:  0.01\n","batch size:  5 learning rate:  0.02\n","batch size:  7 learning rate:  0.005\n","batch size:  7 learning rate:  0.01\n","batch size:  7 learning rate:  0.02\n","batch size:  9 learning rate:  0.005\n","batch size:  9 learning rate:  0.01\n","batch size:  9 learning rate:  0.02\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6y29_IKaQAjy","executionInfo":{"status":"ok","timestamp":1632461457602,"user_tz":-540,"elapsed":116116,"user":{"displayName":"뚜뚜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYh6WlXFq1X6XUJHBbCx-VfyZqesyHJAoYJep2Yw=s64","userId":"15837783100942680972"}},"outputId":"9561cbfe-295c-4c5f-a903-8d5e6fefdee1"},"source":["results = []\n","\n","for batch_size in batch_sizes:\n","  for learning_rate in learning_rates:\n","    print(batch_size, learning_rate)\n","    for train_index, test_index in kf.split(scaled_X):\n","      scaled_X_train, scaled_X_test = scaled_X[train_index], scaled_X[test_index]\n","      scaled_y_train, scaled_y_test = scaled_y[train_index], scaled_y[test_index]\n","      y_test = y[test_index]\n","\n","      # training\n","      model = keras.Sequential(\n","          [\n","              layers.InputLayer(input_shape=scaled_X_train.shape[-1]),\n","              layers.Dense(96, activation='relu'), # (0.1439302, 0.123, 0.999) --> (23, 0, 255)\n","              layers.Dense(48, activation='relu'),\n","              layers.Dense(1)\n","          ]\n","      )\n","\n","      #model.compile(loss=\"mse\", optimizer=\"adam\")\n","\n","      opt = keras.optimizers.Adam(learning_rate=0.005)\n","      model.compile(loss=\"mse\", optimizer=opt)\n","\n","      early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7)\n","      model.fit(scaled_X_train, scaled_y_train, \n","                batch_size=1, epochs=150, \n","                callbacks=[early_stopping_callback], validation_split=0.05, verbose='auto')\n","\n","      # evaluation\n","      pred = model.predict(scaled_X_test).reshape((-1, 1))\n","      pred = y_min_max_scaler.inverse_transform(pred)\n","      rmse = np.sqrt(metrics.mean_squared_error(y_test, pred))\n","\n","      print(rmse)\n","      print(\"---------------------\")\n","\n","      #results를 딕셔너리 형식으로 설정\n","      #batchsize와 learning_rate, rmse를 각각 저장토록 함\n","      result = {}\n","      result['batch_size'] = batch_size\n","      result['learning_rate'] = learning_rate\n","      result['rmse'] = rmse\n","\n","      results.append(result)\n","      #fianl_rmses.append(rmse)\n","      break\n","\n","    #break  #일단 한 세트에 대해서만 학습해보자. batchsize 1, learnig_size 0.005를 실행시 rmse 등장\n","  break"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["1 0.005\n","Epoch 1/150\n","1248/1248 [==============================] - 2s 2ms/step - loss: 0.0073 - val_loss: 0.0017\n","Epoch 2/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0046 - val_loss: 0.0020\n","Epoch 3/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0055 - val_loss: 0.0024\n","Epoch 4/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0045 - val_loss: 0.0027\n","Epoch 5/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0032 - val_loss: 0.0026\n","Epoch 6/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0029 - val_loss: 0.0020\n","Epoch 7/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0032 - val_loss: 0.0023\n","Epoch 8/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0025 - val_loss: 0.0026\n","35982.202282662605\n","---------------------\n","1 0.01\n","Epoch 1/150\n","1248/1248 [==============================] - 2s 2ms/step - loss: 0.0066 - val_loss: 0.0027\n","Epoch 2/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0049 - val_loss: 0.0021\n","Epoch 3/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0056 - val_loss: 0.0028\n","Epoch 4/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0035 - val_loss: 0.0026\n","Epoch 5/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0034 - val_loss: 0.0026\n","Epoch 6/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0028 - val_loss: 0.0020\n","Epoch 7/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0026 - val_loss: 0.0026\n","Epoch 8/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0026 - val_loss: 0.0024\n","Epoch 9/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0025 - val_loss: 0.0016\n","Epoch 10/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0023 - val_loss: 0.0016\n","Epoch 11/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0025 - val_loss: 0.0018\n","Epoch 12/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0022 - val_loss: 0.0017\n","Epoch 13/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0023 - val_loss: 0.0060\n","Epoch 14/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0025 - val_loss: 0.0018\n","Epoch 15/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0024 - val_loss: 0.0015\n","Epoch 16/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0023 - val_loss: 0.0016\n","Epoch 17/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0021 - val_loss: 0.0021\n","Epoch 18/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0023 - val_loss: 0.0024\n","Epoch 19/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0020 - val_loss: 0.0018\n","Epoch 20/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0020 - val_loss: 0.0017\n","Epoch 21/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0020 - val_loss: 0.0019\n","Epoch 22/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0020 - val_loss: 0.0016\n","21973.41370919617\n","---------------------\n","1 0.02\n","Epoch 1/150\n","1248/1248 [==============================] - 2s 2ms/step - loss: 0.0070 - val_loss: 0.0041\n","Epoch 2/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0047 - val_loss: 0.0022\n","Epoch 3/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0042 - val_loss: 0.0019\n","Epoch 4/150\n","1248/1248 [==============================] - 2s 2ms/step - loss: 0.0042 - val_loss: 0.0025\n","Epoch 5/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0032 - val_loss: 0.0022\n","Epoch 6/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0027 - val_loss: 0.0033\n","Epoch 7/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0028 - val_loss: 0.0015\n","Epoch 8/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0035 - val_loss: 0.0017\n","Epoch 9/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0029 - val_loss: 0.0017\n","Epoch 10/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0029 - val_loss: 0.0019\n","Epoch 11/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0027 - val_loss: 0.0024\n","Epoch 12/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0026 - val_loss: 0.0018\n","Epoch 13/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0024 - val_loss: 0.0014\n","Epoch 14/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0022 - val_loss: 0.0016\n","Epoch 15/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0023 - val_loss: 0.0019\n","Epoch 16/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0020 - val_loss: 0.0038\n","Epoch 17/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0020 - val_loss: 0.0027\n","Epoch 18/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0029 - val_loss: 0.0020\n","Epoch 19/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0019 - val_loss: 0.0014\n","Epoch 20/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0018 - val_loss: 0.0019\n","Epoch 21/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0018 - val_loss: 0.0015\n","Epoch 22/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0018 - val_loss: 0.0014\n","Epoch 23/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0019 - val_loss: 0.0012\n","Epoch 24/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0017 - val_loss: 0.0014\n","Epoch 25/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0017 - val_loss: 0.0019\n","Epoch 26/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0018 - val_loss: 0.0020\n","Epoch 27/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0016 - val_loss: 0.0013\n","Epoch 28/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0017 - val_loss: 0.0020\n","Epoch 29/150\n","1248/1248 [==============================] - 2s 1ms/step - loss: 0.0016 - val_loss: 0.0021\n","Epoch 30/150\n","1248/1248 [==============================] - 2s 2ms/step - loss: 0.0017 - val_loss: 0.0018\n","28741.543892787908\n","---------------------\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E2hDlpCNSfoo","executionInfo":{"status":"ok","timestamp":1632461523137,"user_tz":-540,"elapsed":328,"user":{"displayName":"뚜뚜","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjYh6WlXFq1X6XUJHBbCx-VfyZqesyHJAoYJep2Yw=s64","userId":"15837783100942680972"}},"outputId":"70100d86-d453-4dd9-a65e-fee325496f00"},"source":["results \n","#batch는 1, learningrate는 0.01에서 가장 좋았다.\n","#따라서, 다음번에 돌릴 땐 이 값 근처에서 촘촘히 돌리면 된다."],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'batch_size': 1, 'learning_rate': 0.005, 'rmse': 35982.202282662605},\n"," {'batch_size': 1, 'learning_rate': 0.01, 'rmse': 21973.41370919617},\n"," {'batch_size': 1, 'learning_rate': 0.02, 'rmse': 28741.543892787908}]"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"ccJzKIztS2ls"},"source":["\"\"\"\n","Random search\n","\"\"\"\n","import random\n","batch_sizes = random.sample(range(1, 11), 5)\n","leraning_rates = np.random.uniform(low = 0.005, high = 0.1, size = (4,))\n","#자원이 충분하다면, 위의 랜덤서치를 이용해 해결도 가능"],"execution_count":null,"outputs":[]}]}